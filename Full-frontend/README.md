# Context Search Engine - Full Frontend Application

This is the complete web application implementation of the Context Search Engine for Construction Documents. It provides a full-stack solution with Flask backend, web interface, and comprehensive document processing capabilities.

## ğŸš€ Features

- **Web Interface**: Clean, responsive Flask application
- **File Upload**: Drag-and-drop PDF and image upload
- **Real-time Processing**: Live progress updates during analysis
- **AI Integration**: Multiple AI models (Gemini primary, Gemma fallback)
- **Report Generation**: Automatic CSV and PDF report creation
- **Material Database**: Comprehensive construction material recognition

## ğŸ› ï¸ Quick Start

1. **Navigate to the directory**:
   ```bash
   cd Full-frontend
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment**:
   ```bash
   # Download SpaCy model
   python -m spacy download en_core_web_sm

   # Create .env file with your API keys
   # GEMINI_API_KEY_1=your_key_here
   # GEMINI_API_KEY_2=your_key_here
   # GEMINI_API_KEY_3=your_key_here
   # OPENROUTER_API_KEY=your_key_here
   ```

4. **Run the application**:
   ```bash
   python app.py
   ```

5. **Open browser**: http://localhost:5000

## ğŸ“ File Structure

```
Full-frontend/
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ ai_buddy.py           # AI model integration
â”œâ”€â”€ document_processor.py # PDF/Image text extraction
â”œâ”€â”€ material_extractor.py # NLP material identification
â”œâ”€â”€ output_generator.py   # CSV/PDF report generation
â”œâ”€â”€ search_engine.py      # FAISS semantic search
â”œâ”€â”€ create_index.py       # Index creation utilities
â”œâ”€â”€ evaluation.py         # Model evaluation scripts
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html       # Main upload page
â”‚   â””â”€â”€ pdf_template.html # PDF report template
â”œâ”€â”€ uploads/             # Temporary file storage
â”œâ”€â”€ downloads/           # Generated reports
â”œâ”€â”€ faiss_index.idx      # Pre-built search index
â”œâ”€â”€ index_to_chunk.pkl   # Index mappings
â””â”€â”€ .gitignore          # Git ignore rules
```

## ğŸ”§ API Configuration

The application uses multiple AI services for robustness:

- **Primary**: Google Gemini 2.0 Flash (with key rotation)
- **Fallback**: OpenRouter Gemma model
- **Keys**: Stored in `.env` file (never committed to git)

## ğŸ“Š Processing Pipeline

1. **Upload**: File validation and storage
2. **Extraction**: Text extraction from PDF/image
3. **Search**: Hybrid keyword + semantic search
4. **Analysis**: SpaCy NLP for material properties
5. **Refinement**: AI enhancement of extracted data
6. **Output**: Web display + downloadable reports

## ğŸ›¡ï¸ Security Features

- API keys stored in environment variables
- File upload validation and cleanup
- Secure temporary file handling
- No sensitive data in source code

## ğŸ” Supported Materials

The system recognizes 50+ construction materials including:
- Cement, Concrete, Steel, Aggregate
- Waterproofing, Admixtures, Reinforcement
- Timber, Glass, Insulation materials
- And many more construction-specific materials

## ğŸ“ˆ Performance

- **Processing Speed**: ~30 seconds for typical documents
- **Accuracy**: 85%+ material identification
- **Scalability**: Handles documents up to 100MB
- **Memory Efficient**: Optimized FAISS indexing

## ğŸ› Troubleshooting

**Common Issues**:

1. **Tesseract not found**: Install Tesseract OCR
2. **API key errors**: Check `.env` file configuration
3. **Memory errors**: Reduce batch size in `ai_buddy.py`
4. **Model download**: Run `python -m spacy download en_core_web_sm`

## ğŸ¤ Development

To contribute or modify:

1. Create feature branch
2. Make changes
3. Test with sample documents
4. Submit pull request

## ğŸ“ Support

For technical issues, check the logs in the Flask console output or create a GitHub issue.

---

**Part of the NLP Hackathon Context Search Engine Project**
